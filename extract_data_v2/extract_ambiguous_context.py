import json
import csv
from collections import defaultdict, Counter
import os

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
INPUT_JSON = "Bukhari/Bukhari_Without_Tashkel_results_advanced_with_matn.json"
OUTPUT_CSV = "Bukhari/ambiguous_narrators_for_llm.csv"

# Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªÙŠ Ù†Ø±ÙŠØ¯ ÙÙƒ Ù„Ø¨Ø³Ù‡Ø§ (ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© Ø£Ùˆ Ø£Ø³Ù…Ø§Ø¡ Ø´Ø§Ø¦Ø¹Ø© Ø¬Ø¯Ø§Ù‹)
TARGET_NAMES = {
    'Ø³ÙÙŠØ§Ù†', 'Ø­Ù…Ø§Ø¯', 'Ø¥Ø³Ù…Ø§Ø¹ÙŠÙ„', 'Ù‡Ø´Ø§Ù…', 'ÙŠØ­ÙŠÙ‰', 'Ø¥Ø¨Ø±Ø§Ù‡ÙŠÙ…', 
    'Ø¹Ù…Ø±Ùˆ', 'Ø¹Ø¨ÙŠØ¯ Ø§Ù„Ù„Ù‡', 'Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡', 'Ø£Ø¨ÙŠÙ‡', 'Ø£Ø¨ÙŠ', 
    'Ø´Ø¹Ø¨Ø©', 'Ø³Ø¹ÙŠØ¯', 'Ø§Ù„Ø­ÙƒÙ…', 'Ù…ÙˆØ³Ù‰', 'Ù…Ø³Ù„Ù…', 'Ø®Ø§Ù„Ø¯',
    'Ø§Ù„Ù„ÙŠØ«', 'Ù…Ø§Ù„Ùƒ', 'Ø«Ø§Ø¨Øª', 'Ù‚ØªØ§Ø¯Ø©', 'Ø³Ù„ÙŠÙ…Ø§Ù†'
}

def is_ambiguous(name):
    # Ù†Ø¹ØªØ¨Ø± Ø§Ù„Ø§Ø³Ù… ØºØ§Ù…Ø¶Ø§Ù‹ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
    # Ø£Ùˆ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙƒÙˆÙ†Ø§Ù‹ Ù…Ù† ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© (ÙˆÙ„Ø§ ÙŠØ¨Ø¯Ø£ Ø¨Ù€ Ø¹Ø¨Ø¯/Ø£Ø¨Ùˆ/Ø§Ø¨Ù†)
    name = name.strip()
    if name in TARGET_NAMES:
        return True
    
    parts = name.split()
    if len(parts) == 1 and name not in ['Ø§Ù„Ù†Ø¨ÙŠ', 'Ø±Ø³ÙˆÙ„ Ø§Ù„Ù„Ù‡']:
        return True
        
    return False

def extract_contexts():
    if not os.path.exists(INPUT_JSON):
        print("âŒ File not found.")
        return

    print(f"ğŸ“‚ Loading data from {INPUT_JSON}...")
    with open(INPUT_JSON, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # Dictionary format:
    # { "Ambiguous Name": Counter({ "Student Name 1": count, "Student Name 2": count }) }
    context_map = defaultdict(Counter)

    print("ğŸ” Extracting relationships...")
    for hadith in data:
        if "chains" in hadith:
            for chain in hadith["chains"]:
                narrators = chain["narrators"]
                
                for i, narrator in enumerate(narrators):
                    raw_name = narrator["name"].strip()
                    
                    if is_ambiguous(raw_name):
                        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªÙ„Ù…ÙŠØ° (Ø§Ù„Ø±Ø§ÙˆÙŠ Ø§Ù„Ø³Ø§Ø¨Ù‚ ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©)
                        # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø¹Ø§Ø¯Ø©: [Ø§Ù„ØªÙ„Ù…ÙŠØ° (Ø§Ù„Ø£Ø­Ø¯Ø«), Ø§Ù„Ø´ÙŠØ® (Ø§Ù„Ø£Ù‚Ø¯Ù…), ...]
                        if i > 0:
                            student_name = narrators[i-1]["name"].strip()
                        else:
                            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ùˆ Ø§Ù„Ø£ÙˆÙ„ ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©ØŒ ÙØ§Ù„ØªÙ„Ù…ÙŠØ° Ù‡Ùˆ "Ø§Ù„Ø¨Ø®Ø§Ø±ÙŠ"
                            student_name = "Ø§Ù„Ø¨Ø®Ø§Ø±ÙŠ (Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø³Ù†Ø¯)"
                        
                        context_map[raw_name][student_name] += 1

    # ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ CSV
    print(f"ğŸ’¾ Saving report to {OUTPUT_CSV}...")
    with open(OUTPUT_CSV, 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f)
        # Ø§Ù„Ø±Ø¤ÙˆØ³: Ø§Ù„Ø§Ø³Ù… Ø§Ù„ØºØ§Ù…Ø¶ØŒ Ø§Ù„ØªÙ„Ù…ÙŠØ°ØŒ Ø§Ù„ØªÙƒØ±Ø§Ø±ØŒ (Ø®Ø§Ù†Ø© ÙØ§Ø±ØºØ© Ù„Ù„Ù€ LLM)
        writer.writerow(['Ambiguous Name', 'Student (Narrator From)', 'Frequency', 'Full Name (LLM Prediction)'])
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹ Ø£ÙˆÙ„Ø§Ù‹
        sorted_names = sorted(context_map.keys(), key=lambda k: sum(context_map[k].values()), reverse=True)
        
        for name in sorted_names:
            students = context_map[name]
            # Ù†Ø£Ø®Ø° Ø£Ù‡Ù… Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° (Ø§Ù„Ø°ÙŠÙ† Ø±ÙˆÙˆØ§ Ø¹Ù†Ù‡ Ø£ÙƒØ«Ø± Ù…Ù† Ù…Ø±Ø©) Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
            for student, count in students.most_common():
                if count >= 2: # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù†Ø§Ø¯Ø±Ø© Ø¬Ø¯Ø§Ù‹ Ù„ØªÙˆÙÙŠØ± Ø§Ù„ØªÙˆÙƒÙŠØ² Ù„Ù„Ù€ LLM
                    writer.writerow([name, student, count, ''])

    print("âœ… Done! File ready for LLM processing.")
    print("ğŸ‘‰ Upload 'ambiguous_narrators_for_llm.csv' to Gemini/ChatGPT with the prompt provided.")

if __name__ == "__main__":
    extract_contexts()