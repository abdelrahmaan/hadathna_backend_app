# Narrator Disambiguation Verification Plan

## ğŸ¯ Goal

Achieve **98%+ verified accuracy** with **99.7% coverage** for narrator name disambiguation before Neo4j ingestion.

**Principle:** Better to have 99.7% coverage with 98%+ accuracy than 100% coverage with unknown errors.

---

## ğŸ“Š Current Status (Baseline)

| Metric | Value | Notes |
|--------|-------|-------|
| **Total narrator mentions** | 44,733 | All narrator instances in Bukhari |
| **Coverage** | 75.1% | 33,573 resolved / 44,733 total |
| **Context resolution** | 97.0% | 1,509 / 1,555 context pairs |
| **Pronoun resolution (Ø£Ø¨ÙŠÙ‡/Ø£Ø¨ÙŠ)** | 90.7% | 751 / 828 cases |
| **Unique narrators** | 2,585 | After normalization |

### âš ï¸ Critical Issues Identified

1. **Unknown accuracy** - 97% resolution but no verification against scholarly sources
2. **Over-aggressive substring matching** - `if 'Ù†Ø§ÙØ¹' in student` matches unintended cases
3. **Broken Ø§Ù„Ø¨Ø®Ø§Ø±ÙŠ fallback** - `Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡|Ø§Ù„Ø¨Ø®Ø§Ø±ÙŠ â†’ Ø§Ø¨Ù† Ø§Ù„Ù…Ø¨Ø§Ø±Ùƒ` is historically incorrect
4. **Incomplete father_lookup** - Missing ~30% of father-son pairs
5. **No validation mechanism** - Zero test suite, no cross-reference

---

## ğŸ”¬ Verification Strategy

### Phase 1: Extract Verification Dataset (2-3 hours)

**Create:** `verify_disambiguation.py`

**Purpose:** Extract all resolutions with metadata for manual review

**Output:** `verification_dataset.csv` with columns:
- `hadith_number` - Hadith reference
- `chain_index` - Chain position
- `narrator_position` - Position in chain
- `original_name` - Raw name from JSON
- `resolved_name` - After disambiguation
- `student_name` - Context (previous narrator)
- `resolution_method` - "context_json" / "live_rule" / "static_mapping" / "identity"
- `confidence` - "high" / "medium" / "low"
- `needs_review` - Boolean flag

**Confidence levels:**
- **HIGH:** Exact match in context JSON, unambiguous names (Ø¹Ø§Ø¦Ø´Ø©, Ù…Ø§Ù„Ùƒ, Ø£Ù†Ø³)
- **MEDIUM:** Live rule with multiple conditions (Ø³ÙÙŠØ§Ù† with 3+ student checks)
- **LOW:** Single substring match, defaults (e.g., `student == 'Ø³Ø¹ÙŠØ¯'`)

**Auto-flag for review:**
- Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ resolutions with substring-only matches
- Ø£Ø¨ÙŠÙ‡ resolutions using short name defaults
- Any resolution where student = Ø§Ù„Ø¨Ø®Ø§Ø±ÙŠ
- Unresolved cases (77 pronouns + 50 Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡)

---

### Phase 2: Fix Systematic Errors (1-2 hours)

#### 2.1 Fix Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ rules (HIGHEST PRIORITY)

**File:** `solve_ambiguity.py` lines 327-362

**Fix 1: Remove broken Ø§Ù„Ø¨Ø®Ø§Ø±ÙŠ fallback**
```python
# BEFORE:
if 'Ø§Ù„Ø¨Ø®Ø§Ø±ÙŠ' in student:
    return 'Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ Ø¨Ù† Ø§Ù„Ù…Ø¨Ø§Ø±Ùƒ'  # âŒ WRONG

# AFTER:
if 'Ø§Ù„Ø¨Ø®Ø§Ø±ÙŠ' in student:
    return None  # âœ“ Mark for manual review
```

**Fix 2: Add specificity to substring matches**
```python
# BEFORE:
if any(s in student for s in ['Ù†Ø§ÙØ¹', 'Ø³Ø§Ù„Ù…', 'Ø­Ù…Ø²Ø©', ...]):
    return 'Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ Ø¨Ù† Ø¹Ù…Ø±'

# AFTER:
if student in ['Ù†Ø§ÙØ¹', 'Ø³Ø§Ù„Ù…', 'Ø­Ù…Ø²Ø©']:  # Exact match first
    return 'Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ Ø¨Ù† Ø¹Ù…Ø±'
elif any(s in student for s in ['Ù†Ø§ÙØ¹ Ù…ÙˆÙ„Ù‰', 'Ø³Ø§Ù„Ù… Ø¨Ù†', 'Ø­Ù…Ø²Ø© Ø¨Ù†']):
    return 'Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ Ø¨Ù† Ø¹Ù…Ø±'
# Otherwise return None
```

**Fix 3: Re-order by statistical frequency**
1. Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ Ø¨Ù† Ø¹Ù…Ø± (Sahabi, most common)
2. Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ Ø¨Ù† Ù…Ø³Ø¹ÙˆØ¯ (Sahabi, very common)
3. Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ Ø¨Ù† Ø¹Ø¨Ø§Ø³ (Sahabi, common)
4. Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ Ø¨Ù† Ø§Ù„Ù…Ø¨Ø§Ø±Ùƒ (Tabi'i, less common)

#### 2.2 Fix Ø£Ø¨ÙŠÙ‡ defaults

**File:** `solve_ambiguity.py` lines 524-552

**Remove over-aggressive defaults:**
```python
# BEFORE:
if student == 'Ø³Ø¹ÙŠØ¯':
    return 'Ø§Ù„Ù…Ø³ÙŠØ¨ Ø¨Ù† Ø­Ø²Ù†'  # Default assumption

# AFTER:
if student == 'Ø³Ø¹ÙŠØ¯':
    return None  # âœ“ Conservative approach
```

**Rationale:** Unresolved data shows 11 cases of `Ø£Ø¨ÙŠÙ‡|Ø³Ø¹ÙŠØ¯` failed â†’ defaults are unreliable

#### 2.3 Add STRICT_MODE flag

```python
# At top of solve_ambiguity.py
STRICT_MODE = True

# When enabled:
# - All substring-only matches return None
# - All defaults return None
# - Only exact matches in father_lookup or multi-condition rules pass
```

---

### Phase 3: Manual Resolution with Scholarly Sources (6-8 hours)

#### 3.1 Reference Sources

**Primary sources:**
1. **ØªÙ‡Ø°ÙŠØ¨ Ø§Ù„ØªÙ‡Ø°ÙŠØ¨** (Tahdhib al-Tahdhib) - Standard biographical dictionary
2. **Ø³ÙŠØ± Ø£Ø¹Ù„Ø§Ù… Ø§Ù„Ù†Ø¨Ù„Ø§Ø¡** (Siyar A'lam al-Nubala) - Biographical encyclopedia
3. **ØªÙ‚Ø±ÙŠØ¨ Ø§Ù„ØªÙ‡Ø°ÙŠØ¨** (Taqrib al-Tahdhib) - Concise biographies
4. **ÙØªØ­ Ø§Ù„Ø¨Ø§Ø±ÙŠ** (Fath al-Bari) - Bukhari commentary with narrator notes
5. **Ø¹Ù…Ø¯Ø© Ø§Ù„Ù‚Ø§Ø±ÙŠ** (Umdat al-Qari) - Alternative Bukhari commentary

**Web sources (verification only):**
- `tarajm.com` (via existing `tarajm/tarajm.py`)
- `islamweb.net` narrator database

#### 3.2 Resolve 127 unresolved cases

**Process:**
1. Look up narrator in biographical dictionaries
2. Identify all possible candidates
3. Check student-teacher relationships
4. Record resolution with **citation**

**Output format:** `manual_resolutions.json`
```json
{
  "Ø£Ø¨ÙŠÙ‡|ÙŠØ¹Ù‚ÙˆØ¨": {
    "resolved_name": "Ø¥Ø¨Ø±Ø§Ù‡ÙŠÙ… Ø¨Ù† Ø³Ø¹Ø¯",
    "confidence": "high",
    "source": "Tahdhib al-Tahdhib vol. 8 p. 234 - ÙŠØ¹Ù‚ÙˆØ¨ Ø¨Ù† Ø¥Ø¨Ø±Ø§Ù‡ÙŠÙ… Ø¨Ù† Ø³Ø¹Ø¯",
    "reasoning": "ÙŠØ¹Ù‚ÙˆØ¨ is son of Ø¥Ø¨Ø±Ø§Ù‡ÙŠÙ… Ø¨Ù† Ø³Ø¹Ø¯, confirmed in biography",
    "verified_by": "human",
    "verification_date": "2026-02-10"
  }
}
```

#### 3.3 Verify high-confidence resolutions (sampling)

**Sample size:** 100 cases (stratified random)

**Stratification:**
- 30 Ø³ÙÙŠØ§Ù† resolutions (15 Ø§Ù„Ø«ÙˆØ±ÙŠ, 15 Ø¨Ù† Ø¹ÙŠÙŠÙ†Ø©)
- 30 Ù‡Ø´Ø§Ù… resolutions (20 Ø¨Ù† Ø¹Ø±ÙˆØ©, 5 each of others)
- 20 ÙŠØ­ÙŠÙ‰ resolutions
- 10 Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ resolutions
- 10 Ø£Ø¨ÙŠÙ‡ resolutions

**Success criteria:** â‰¥95% accuracy â†’ If <95%, expand to 500 cases

---

### Phase 4: Integration & Final Verification (2-3 hours)

#### 4.1 Integrate manual resolutions

**Update solve_ambiguity.py:**

```python
# Load manual overrides
MANUAL_RESOLUTIONS = load_manual_resolutions()

# Resolution priority:
def resolve_ambiguous(name, student):
    context_key = f"{name}|{student}"

    # STEP 0: Manual overrides (100% verified)
    if context_key in MANUAL_RESOLUTIONS:
        return MANUAL_RESOLUTIONS[context_key]['resolved_name']

    # STEP 1: High-confidence rules (multi-condition, exact matches)
    # STEP 2: Medium-confidence rules (single exact match)
    # STEP 3: Return None (needs review)
```

#### 4.2 Generate verification report

**File:** `VERIFICATION_REPORT.md`

**Contents:**
- Summary statistics
- Verification methods breakdown
- Accuracy validation (100-case sample results)
- Scholarly sources used
- Known limitations
- Audit trail with citations

#### 4.3 Create test suite

**File:** `test_disambiguation.py`

```python
def test_sufyan_disambiguation():
    """Test Ø³ÙÙŠØ§Ù† resolution based on verified Bukhari cases"""
    assert resolve_ambiguous('Ø³ÙÙŠØ§Ù†', 'Ø§Ù„Ø­Ù…ÙŠØ¯ÙŠ') == 'Ø³ÙÙŠØ§Ù† Ø¨Ù† Ø¹ÙŠÙŠÙ†Ø©'
    assert resolve_ambiguous('Ø³ÙÙŠØ§Ù†', 'ÙŠØ­ÙŠÙ‰') == 'Ø³ÙÙŠØ§Ù† Ø§Ù„Ø«ÙˆØ±ÙŠ'

def test_no_hallucination():
    """Ensure unknown cases return None, not guesses"""
    assert resolve_ambiguous('Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡', 'unknown_student') is None
    assert resolve_ambiguous('Ø£Ø¨ÙŠÙ‡', 'Ø§Ù„Ø¨Ø®Ø§Ø±ÙŠ') is None
```

**Run:** `pytest test_disambiguation.py -v`

---

### Phase 5: Final Output Generation (1 hour)

#### 5.1 Regenerate all outputs

```bash
cd extract_data_v2
python3 solve_ambiguity.py  # With STRICT_MODE + manual_resolutions
python3 narrators_mapping.py  # Final normalized output
```

#### 5.2 Generate audit files

1. **`disambiguation_audit.csv`** - Every resolution with source
2. **`unresolved_cases.csv`** - Cases needing future work
3. **`verification_sample.csv`** - 100 verified cases for audit

---

## âœ… Success Criteria (MUST achieve before Neo4j ingestion)

1. **Accuracy:** 98%+ verified on 100-case sample
2. **Coverage:** 99%+ of mentions resolved (allow 0.3% unresolved for edge cases)
3. **Audit trail:** Every resolution traceable to source (rule/manual/static)
4. **No hallucinations:** Unresolved cases marked as such, not guessed
5. **Test suite:** 50+ test cases passing from verified Bukhari examples
6. **Documentation:** VERIFICATION_REPORT.md with scholarly citations

---

## âŒ NOT Acceptable

1. Guessing on ambiguous cases
2. Resolutions without verification path
3. Substring-only matches without confirmation
4. Defaults that failed in unresolved data

---

## ğŸ“ Critical Files to Modify

| File | Action | Lines | Purpose |
|------|--------|-------|---------|
| `solve_ambiguity.py` | MODIFY | 327-362 | Fix Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ rules |
| `solve_ambiguity.py` | MODIFY | 524-552 | Fix Ø£Ø¨ÙŠÙ‡ defaults |
| `solve_ambiguity.py` | ADD | Top | Add STRICT_MODE flag |
| `solve_ambiguity.py` | ADD | 250-260 | Add load_manual_resolutions() |
| `verify_disambiguation.py` | CREATE | - | Extract verification dataset |
| `test_disambiguation.py` | CREATE | - | Test suite with verified cases |
| `manual_resolutions.json` | CREATE | - | Manually verified resolutions |
| `VERIFICATION_REPORT.md` | CREATE | - | Full audit report |

---

## â±ï¸ Implementation Timeline

| Phase | Duration | Description |
|-------|----------|-------------|
| **Phase 1** | 2-3 hours | Create verification extraction script, generate dataset |
| **Phase 2** | 1-2 hours | Fix systematic errors in solve_ambiguity.py |
| **Phase 3** | 6-8 hours | Manual resolution of 127 cases with scholarly research |
| **Phase 4** | 2-3 hours | Integration, sampling verification (100 cases) |
| **Phase 5** | 1 hour | Final regeneration, reports, test suite |
| **TOTAL** | **12-17 hours** | Careful, research-grade work |

---

## ğŸ” Quality Assurance Methodology

For **100% accuracy without hallucination**, we use:

1. **Conservative resolution:** When in doubt, mark as unresolved
2. **Multi-source verification:** Cross-check 3+ biographical sources
3. **Explicit citations:** Every manual resolution has source reference
4. **Test-driven:** Write tests from verified Bukhari cases first
5. **Stratified sampling:** Verify random sample across all rule categories
6. **Peer review:** Manual resolutions reviewed by hadith scholar (if available)

---

## ğŸ“š Next Steps After Verification

1. Complete all 5 phases above
2. Achieve 98%+ accuracy on verification sample
3. Generate VERIFICATION_REPORT.md
4. **Only then** proceed to Neo4j ingestion
5. Use verified data for graph analysis

---

## ğŸ“– Related Documentation

- [`DISAMBIGUATION_RESULTS.md`](DISAMBIGUATION_RESULTS.md) - Current results with Arabic explanations
- [`solve_ambiguity.py`](solve_ambiguity.py) - Disambiguation rules engine
- [`narrators_mapping.py`](narrators_mapping.py) - Main normalization pipeline
- [`tarajm/tarajm.py`](../tarajm/tarajm.py) - Biography fetching tool

---

**Generated:** 2026-02-10
**Status:** Plan approved, ready for implementation
**Approach:** Research-grade verification prioritizing accuracy over coverage
